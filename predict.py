# Prediction interface for Cog ⚙️
# https://github.com/replicate/cog/blob/main/docs/python.md

import os
import shutil
import langid
import torch
import se_extractor

from cog import BasePredictor, Input, Path
from api import BaseSpeakerTTS, ToneColorConverter

SUPPORTED_LANGUAGES = ["zh", "en"]


class Predictor(BasePredictor):
    def setup(self) -> None:
        """Load the model into memory to make running multiple predictions efficient"""
        ckpt_base = "checkpoints/base_speakers/EN"
        ckpt_converter = "checkpoints/converter"
        device = "cuda:0"

        self.base_speaker_tts = BaseSpeakerTTS(
            f"{ckpt_base}/config.json", device=device
        )
        self.base_speaker_tts.load_ckpt(f"{ckpt_base}/checkpoint.pth")

        self.tone_color_converter = ToneColorConverter(
            f"{ckpt_converter}/config.json", device=device
        )
        self.tone_color_converter.load_ckpt(f"{ckpt_converter}/checkpoint.pth")

        # Obtain Tone Color Embedding
        self.source_se = torch.load(f"{ckpt_base}/en_default_se.pth").to(device)

    def predict(
        self,
        prompt: str = Input(
            description="Input text prompt. Only supports English or Chinese text. Text length limited to 200 characters for this demo.",
            default="This audio is generated by OpenVoice.",
        ),
        audio: Path = Input(description="Input audio."),
        style: str = Input(
            description="Select a style of output audio for the synthesised speech. Chinese only supports the default style.",
            choices=[
                "default",
                "whispering",
                "cheerful",
                "terrified",
                "angry",
                "sad",
                "friendly",
            ],
            default="default",
        ),
        speed: float = Input(
            description="Set speed scale of the output audio.", default=1.0
        ),
        agree_terms: bool = Input(
            description="I agree to the terms of the cc-by-nc-4.0 license-: https://github.com/myshell-ai/OpenVoice/blob/main/LICENSE.",
            default=True,
        ),
    ) -> Path:
        """Run a single prediction on the model"""
        assert (
            agree_terms
        ), "To run the demo, you need to agree to to the terms of the cc-by-nc-4.0 license-: https://github.com/myshell-ai/OpenVoice/blob/main/LICENSE."

        assert (
            2 <= len(prompt) <= 200
        ), "Text length limited to 2-200 characters for this demo, please try again."

        # detect the input language
        language_predicted = langid.classify(prompt)[0].strip()
        print(f"Detected language: {language_predicted}")
        assert (
            language_predicted in SUPPORTED_LANGUAGES
        ), f"The detected language {language_predicted} for your input text is not in our Supported Languages: {SUPPORTED_LANGUAGES}."

        language = "Chinese" if language_predicted == "zh" else "English"
        if language_predicted == "zh":
            assert style == "default", "We only support the default style for Chinese."

        target_dir = "cog_processed"
        if os.path.exists(target_dir):
            shutil.rmtree(target_dir)

        target_se, audio_name = se_extractor.get_se(
            str(audio), self.tone_color_converter, target_dir=target_dir, vad=True
        )

        src_path = "tmp.wav"
        self.base_speaker_tts.tts(
            prompt, src_path, speaker=style, language=language, speed=speed
        )

        out_path = "/tmp/out.wav"
        encode_message = "@MyShell"
        self.tone_color_converter.convert(
            audio_src_path=src_path,
            src_se=self.source_se,
            tgt_se=target_se,
            output_path=out_path,
            message=encode_message,
        )
        return Path(out_path)
